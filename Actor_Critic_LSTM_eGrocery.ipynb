{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Fm3qiJNRxKHAWxgIkhlW4ee5eegpomjI",
      "authorship_tag": "ABX9TyNkvr6cpHTTqx5SH4waH+3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srikarraju/eGrocery_Demand_Prediction/blob/main/Actor_Critic_LSTM_eGrocery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCNrY4m-NC_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38d4efb-0d24-4622-b1db-11fe92846b19"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (57.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKirrj7NNB9"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import MultivariateNormal\n",
        "import random\n",
        "import pandas as pd\n",
        "from tensorboardX import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yx9xf2fl7Vu"
      },
      "source": [
        "class EGroceryEnv():\n",
        "\n",
        "\tdef __init__(self, df=pd.DataFrame({0:[0]}), products_count=10, features=['a'], shelf_life=[1], wastage_cost=[1], shortage_cost=[1]):\n",
        "\t\tsuper(EGroceryEnv, self).__init__()\n",
        "\n",
        "\t\tself.df = df\n",
        "\t\tself.products_count = products_count\n",
        "\t\tself.shelf_life = shelf_life\n",
        "\t\tself.features = features\n",
        "\t\tself.wastage_cost = wastage_cost\n",
        "\t\tself.shortage_cost = shortage_cost\n",
        "\t\tself.current_step = 0\n",
        "\t\tself.wastage_track = list([])\n",
        "\t\tself.shortage_track = list([])\n",
        "\t\tself.reward_track = list([])\n",
        "\n",
        "\t\t#variables to track shartage and wastage\n",
        "\t\tself.shortage = np.array(list([0]*self.products_count))\n",
        "\t\tself.wastage = np.array(list([0]*self.products_count))\n",
        "\n",
        "\t\t#Define Stock\n",
        "\t\tself.stock = list([])\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tself.stock.append([0])\n",
        "\t\tprint(features)\n",
        "\n",
        "\n",
        "\tdef _next_observation(self):\n",
        "\n",
        "\t\tobs  = self.df.loc[self.current_step,self.features]\n",
        "\n",
        "\t\tst_temp = list([])\n",
        "\t\tfor i in range(len(self.stock)):\n",
        "\t\t\tfor j in range(1,min(int(self.stock[i][0])+1,5)):\n",
        "\t\t\t\tst_temp.append(self.stock[i][j])\n",
        "\t\t\tif(self.stock[i][0]==5):\n",
        "\t\t\t\tst_temp.append(self.stock[i][4])\n",
        "\t\t\telif(self.stock[i][0]<5):\n",
        "\t\t\t\tfor j in range(int(self.stock[i][0])+1,6):\n",
        "\t\t\t\t\tst_temp.append(0)\n",
        "\t\t\telse:\n",
        "\t\t\t\tst_temp.append(np.sum(self.stock[i][5:int(self.stock[i][0])+1]))\n",
        "\t\tobs = list(obs) + list(st_temp) + list(self.shelf_life)\n",
        "\t\treturn obs\n",
        "\n",
        "\tdef _take_action(self, action):\n",
        "\t\t#Add products to the current stocks\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tif(len(self.stock[i])<self.shelf_life[i]):\n",
        "\t\t\t\tfor j in range(len(self.stock[i]),int(self.shelf_life[i])):\n",
        "\t\t\t\t\tself.stock[i].append(0)\n",
        "\t\t\tself.stock[i].append(action[i])\n",
        "\t\t\tself.stock[i][0]=self.shelf_life[i]\n",
        "\n",
        "\n",
        "\n",
        "\t\t#Fullfill demand\n",
        "\t\tprods = ['prod'+str(i) for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "\t\tdemand = self.df.loc[self.current_step+1,prods]\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tfor j in range(1,int(self.stock[i][0])+1):\n",
        "\t\t\t\tif(self.stock[i][j]>=demand[i]):\n",
        "\t\t\t\t\tself.stock[i][j] = self.stock[i][j] - demand[i]\n",
        "\t\t\t\t\tdemand[i] = 0\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tdemand[i] = demand[i] - self.stock[i][j]\n",
        "\t\t\t\t\tself.stock[i][j] = 0\n",
        "\t\t\tif(demand[i]>0):\n",
        "\t\t\t\tself.shortage[i]=demand[i]\n",
        "\n",
        "\t\t#Update shelf life and find out wastage\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tself.stock[i][0] = self.stock[i][0] -1\n",
        "\t\t\tif(self.stock[i][1]>0):\n",
        "\t\t\t\tself.wastage[i] = self.stock[i][1]\n",
        "\t\t\tfor j in range(1,int(self.stock[i][0])+1):\n",
        "\t\t\t\tself.stock[i][j] = self.stock[i][j+1]\n",
        "\t\t\tself.stock[i].pop()\n",
        "\n",
        "\n",
        "\tdef step(self, action):\n",
        "\t        # update stock, fullfill demand and calculate shortage and wastage\n",
        "\t\tquantity = [6, 10, 15, 4, 6, 2, 7, 50, 2, 30]\n",
        "\t\taction1 = [0]*self.products_count\n",
        "\t\tfor i in range(len(action)):\n",
        "\t\t\taction1[i] = action[i]*quantity[i]\n",
        "\t\tself._take_action(action1)\n",
        "\t\tself.action = action\n",
        "\n",
        "\t\t#increment step\n",
        "\t\tself.current_step += 1\n",
        "\n",
        "\n",
        "\t\treward = -1*(np.matmul(self.wastage_cost,self.wastage.transpose())+np.matmul(self.shortage_cost,self.shortage.transpose()))\n",
        "\t\tself.reward = reward\n",
        "\t\tdone = (self.current_step < 0) or (self.current_step > self.df.shape[0]-2)\n",
        "\n",
        "\t\tobs = self._next_observation()\n",
        "\n",
        "\t\tself.wastage_track.append(np.sum(self.wastage))\n",
        "\t\tself.shortage_track.append(np.sum(self.shortage))\n",
        "\t\tself.reward_track.append(np.abs(self.reward))\n",
        "\n",
        "\n",
        "\t\tself.shortage = np.array(list([0]*self.products_count))\n",
        "\t\tself.wastage = np.array(list([0]*self.products_count))\n",
        "\n",
        "\t\treturn obs, np.sum(self.reward), done, {}\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\t# Reset the state of the environment to an initial state\n",
        "\t\tself.current_step = 0\n",
        "\t\tself.shortage = np.array(list([0]*self.products_count))\n",
        "\t\tself.wastage = np.array(list([0]*self.products_count))\n",
        "\t\tself.stock = list([])\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tself.stock.append([0])\n",
        "\n",
        "\t\t#print(len(self.features),products_count)\n",
        "\t\t#print(self.features)\n",
        "\t\treturn [0]*len(self.features) + [0]*6*self.products_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSaRrxZrNY2h"
      },
      "source": [
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, action_std, lr, betas):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\t#actor\n",
        "        self.actor =  nn.Sequential(\n",
        "                nn.Linear(state_dim, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(512, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(512, 256),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(256, action_dim),\n",
        "\t\tnn.ReLU()\n",
        "                )\n",
        "        # critic\n",
        "        self.critic = nn.Sequential(\n",
        "                nn.Linear(state_dim, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(512, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(512, 256),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(256, 1)\n",
        "                )\n",
        "        #self.device = device\n",
        "        self.action_var = torch.full((action_dim,), action_std*action_std)\n",
        "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=lr, betas=betas)\n",
        "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr, betas=betas)\n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "    def forward(self,state):\n",
        "        action_mean = self.actor(state)\n",
        "        #print(action_var)\n",
        "        action_var = self.action_var.expand_as(action_mean)\n",
        "        #print(action_var)\n",
        "        cov_mat = torch.diag_embed(action_var)\n",
        "\n",
        "        dist = MultivariateNormal(action_mean, cov_mat)\n",
        "\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_value = self.critic(state)\n",
        "        return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
        "\n",
        "    def act(self, state):\n",
        "        state = torch.Tensor(state)\n",
        "        action_mean = self.actor(state)\n",
        "        cov_mat = torch.diag(self.action_var)\n",
        "\n",
        "        dist = MultivariateNormal(action_mean, cov_mat)\n",
        "        action = dist.sample()\n",
        "        action_logprob = dist.log_prob(action)\n",
        "\n",
        "        # memory.states.append(state)\n",
        "        # memory.actions.append(action)\n",
        "        # memory.logprobs.append(action_logprob)\n",
        "\n",
        "        return action.detach()\n",
        "\n",
        "    def evaluate(self, state, action):\n",
        "        action_mean = self.actor(state)\n",
        "\n",
        "        action_var = self.action_var.expand_as(action_mean)\n",
        "        cov_mat = torch.diag_embed(action_var)\n",
        "\n",
        "        dist = MultivariateNormal(action_mean, cov_mat)\n",
        "\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_value = self.critic(state)\n",
        "\n",
        "        return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
        "\n",
        "    def select_action(self, state, memory):\n",
        "        state = torch.FloatTensor(state.reshape(1, -1))\n",
        "        return self.policy_old.act(state, memory).cpu().data.numpy().flatten()\n",
        "\n",
        "    def update(self,trajectory):\n",
        "      for sample in trajectory:\n",
        "        state,action,next_state,reward,done = sample[0],sample[1],sample[2],sample[3],sample[4]\n",
        "        state = torch.Tensor(state)\n",
        "        next_state = torch.Tensor(next_state)\n",
        "        #print(self.critic(state).item())\n",
        "        #print(self.critic(next_state).item())\n",
        "        #print(reward)\n",
        "        td_error = reward + 0.99*self.critic(next_state).item() - self.critic(state).item()\n",
        "        #print(td_error)\n",
        "\n",
        "        loss1 = self.MseLoss(reward + 0.99*self.critic(next_state), self.critic(state))\n",
        "        loss1 = loss1.type(torch.FloatTensor)\n",
        "\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        loss1.mean().backward()\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "\n",
        "        action_logprobs ,_ ,_ = self.evaluate(state,action)\n",
        "        loss2 = td_error*action_logprobs\n",
        "        loss2 = loss2.type(torch.FloatTensor)\n",
        "\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        loss2.mean().backward()\n",
        "        self.actor_optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHZRDQYNl7V3",
        "outputId": "dfdc8cf4-7fc4-409d-e671-439f5ca8d9db"
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/RL_Project/Models/ppo_based/PPOBased/data/final_data_trainx.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/RL_Project/Models/ppo_based/PPOBased/data/final_data_testx.csv')\n",
        "\n",
        "#products_count = 10\n",
        "#products_count = 1\n",
        "products_count = 4\n",
        "\n",
        "# avg_f7 = ['prod'+str(i)+'avg7' for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "# avg_f15 = ['prod'+str(i)+'avg15' for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "# avg_f30 = ['prod'+str(i)+'avg30' for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "\n",
        "\n",
        "avg_f7 = ['prod'+str(i)+'avg7' for i in [8,11,15,17]]\n",
        "avg_f15 = ['prod'+str(i)+'avg15' for i in [8,11,15,17]]\n",
        "avg_f30 = ['prod'+str(i)+'avg30' for i in [8,11,15,17]]\n",
        "\n",
        "# avg_f7 = ['prod'+str(i)+'avg7' for i in [8]]\n",
        "# avg_f15 = ['prod'+str(i)+'avg15' for i in [8]]\n",
        "# avg_f30 = ['prod'+str(i)+'avg30' for i in [8]]\n",
        "\n",
        "features = ['month', 'monthday', 'weekday'] + avg_f7 + avg_f15 + avg_f30\n",
        "\n",
        "print(features)\n",
        "\n",
        "# shelf_life = np.array([4, 3, 5, 10, 7, 2, 1, 3, 8, 6], dtype=np.float32)\n",
        "shelf_life = np.array([4, 3, 5, 10], dtype=np.float32)\n",
        "# shelf_life = np.array([4], dtype=np.float32)\n",
        "\n",
        "wastage_cost = np.array([1]*products_count, dtype=np.float16)\n",
        "shortage_cost = np.array([1]*products_count, dtype=np.float16)\n",
        "\n",
        "action_std = 0.2\n",
        "eps_clip = 0.2\n",
        "gamma = 0.99\n",
        "\n",
        "lr = 0.0001\n",
        "betas = (0.9, 0.999)\n",
        "K_epochs = 5\n",
        "\n",
        "update_timestep = 20\n",
        "time_step=0\n",
        "running_reward = 0\n",
        "\n",
        "state_dim = len(features) + 6*products_count\n",
        "action_dim = products_count\n",
        "\n",
        "env = EGroceryEnv(df_train, products_count, features, shelf_life, wastage_cost, shortage_cost)\n",
        "\n",
        "ac = ActorCritic(state_dim, action_dim, action_std,lr ,betas)\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "Total_reward = []\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['month', 'monthday', 'weekday', 'prod8avg7', 'prod11avg7', 'prod15avg7', 'prod17avg7', 'prod8avg15', 'prod11avg15', 'prod15avg15', 'prod17avg15', 'prod8avg30', 'prod11avg30', 'prod15avg30', 'prod17avg30']\n",
            "['month', 'monthday', 'weekday', 'prod8avg7', 'prod11avg7', 'prod15avg7', 'prod17avg7', 'prod8avg15', 'prod11avg15', 'prod15avg15', 'prod17avg15', 'prod8avg30', 'prod11avg30', 'prod15avg30', 'prod17avg30']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgmEMdvPCwgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ed0aeaa5-4038-4fe7-966c-4747b7bb7fb8"
      },
      "source": [
        "#print(len(features),products_count,state_dim)\n",
        "for epoch in range(0,10000):\n",
        "  #print(\"Environment Initilaized\")\n",
        "  state = env.reset()\n",
        "  #print(len(state))\n",
        "  trajectory = []\n",
        "  total_reward = 0\n",
        "  for step in range(0,730):\n",
        "    #print(state)\n",
        "    #print(\"state:\",state)\n",
        "    state = np.asarray(state,dtype=float)\n",
        "    action = ac.act(state)\n",
        "    next_state,reward,done,_ = env.step(action)\n",
        "    #print(reward)\n",
        "    total_reward += reward\n",
        "    trajectory.append((state,action,next_state,reward,done))\n",
        "    state = next_state\n",
        "    if done==1:\n",
        "      break\n",
        "    if step % update_timestep==0:\n",
        "      ac.update(trajectory)\n",
        "      trajectory = []\n",
        "  print(\"Epoch:\",epoch,total_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 -38971.0\n",
            "Epoch: 1 -45595.0\n",
            "Epoch: 2 -45855.0\n",
            "Epoch: 3 -45789.0\n",
            "Epoch: 4 -45855.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6c617deedfb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_timestep\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mtrajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-96ae0c5f2a04>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, trajectory)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0maction_logprobs\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_error\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0maction_logprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-96ae0c5f2a04>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0maction_logprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdist_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mstate_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m             \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_backward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqhXtiMuIdTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661bfb26-91ce-48da-bbc1-fdf3e32fa950"
      },
      "source": [
        "env2 = EGroceryEnv(df_test, products_count, features, shelf_life, wastage_cost, shortage_cost)\n",
        "state = env2.reset()\n",
        "for step in range(0,30):\n",
        "  #print(\"state:\",state)\n",
        "  state = np.asarray(state,dtype=float)\n",
        "  action = ac.act(state)\n",
        "  print(action)\n",
        "  next_state,reward,done,_ = env2.step(action)\n",
        "  print(reward)\n",
        "  state = next_state\n",
        "print(env2.reward_track)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['month', 'monthday', 'weekday', 'prod8avg7', 'prod11avg7', 'prod15avg7', 'prod17avg7', 'prod8avg15', 'prod11avg15', 'prod15avg15', 'prod17avg15', 'prod8avg30', 'prod11avg30', 'prod15avg30', 'prod17avg30']\n",
            "tensor([-0.0929,  0.2997,  0.2224, -0.0275])\n",
            "-100.0\n",
            "tensor([-0.2205, -0.0048, -0.0062, -0.0723])\n",
            "-88.0\n",
            "tensor([-0.1712,  0.0304,  0.0430, -0.4137])\n",
            "-102.0\n",
            "tensor([-0.1281,  0.1017, -0.4770,  0.0581])\n",
            "-75.0\n",
            "tensor([-0.1441, -0.3436, -0.2075, -0.0897])\n",
            "-90.0\n",
            "tensor([ 0.3813,  0.0340,  0.2729, -0.0158])\n",
            "-133.0\n",
            "tensor([-0.0874, -0.2199,  0.2122,  0.1482])\n",
            "-96.0\n",
            "tensor([-0.0824,  0.2735, -0.1354,  0.0586])\n",
            "-109.0\n",
            "tensor([-0.3401,  0.0551,  0.0183,  0.0613])\n",
            "-134.0\n",
            "tensor([-0.3479,  0.3867, -0.1819,  0.2928])\n",
            "-52.0\n",
            "tensor([-0.2064,  0.1083, -0.0263,  0.1240])\n",
            "-60.0\n",
            "tensor([-0.0569, -0.0800, -0.2358, -0.1010])\n",
            "-95.0\n",
            "tensor([-0.1455,  0.0637,  0.1313, -0.4064])\n",
            "-116.0\n",
            "tensor([ 0.1891, -0.1961,  0.0300, -0.1582])\n",
            "-88.0\n",
            "tensor([ 0.4544,  0.0338,  0.4091, -0.0893])\n",
            "-46.0\n",
            "tensor([ 0.1060, -0.1061,  0.2448,  0.1245])\n",
            "-131.0\n",
            "tensor([-0.0488, -0.2168,  0.0856, -0.3232])\n",
            "-134.0\n",
            "tensor([-0.2219,  0.0788,  0.1427, -0.0524])\n",
            "-101.0\n",
            "tensor([-0.0556, -0.2575,  0.0731, -0.0710])\n",
            "-103.0\n",
            "tensor([-0.4280, -0.1220, -0.1863, -0.0694])\n",
            "-105.0\n",
            "tensor([-0.0282,  0.0084, -0.0032,  0.0468])\n",
            "-102.0\n",
            "tensor([0.2060, 0.0265, 0.0142, 0.2378])\n",
            "-67.0\n",
            "tensor([ 0.4409,  0.0032, -0.3367, -0.1207])\n",
            "-79.0\n",
            "tensor([ 0.1274, -0.2551, -0.1359, -0.3889])\n",
            "-74.0\n",
            "tensor([-0.0998,  0.0792, -0.0703,  0.1559])\n",
            "-62.0\n",
            "tensor([-0.0152, -0.1999, -0.0503,  0.0378])\n",
            "-86.0\n",
            "tensor([-0.2028,  0.0024,  0.0710, -0.1880])\n",
            "-135.0\n",
            "tensor([ 0.1019, -0.0864,  0.2921, -0.0493])\n",
            "-153.0\n",
            "tensor([ 0.0442, -0.3743,  0.0615,  0.3069])\n",
            "-142.0\n",
            "tensor([ 0.2115, -0.0416,  0.0708, -0.1789])\n",
            "-142.0\n",
            "[100.0, 88.0, 102.0, 75.0, 90.0, 133.0, 96.0, 109.0, 134.0, 52.0, 60.0, 95.0, 116.0, 88.0, 46.0, 131.0, 134.0, 101.0, 103.0, 105.0, 102.0, 67.0, 79.0, 74.0, 62.0, 86.0, 135.0, 153.0, 142.0, 142.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pneJEWNJEGS",
        "outputId": "3d342706-f9d3-4af2-fde9-5f4068ef27c1"
      },
      "source": [
        "print(sum(env2.reward_track)/len(env2.reward_track))\n",
        "print(env2.wastage_track)\n",
        "print(env2.shortage_track)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.0\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[100, 88, 102, 75, 90, 133, 96, 109, 134, 52, 60, 95, 116, 88, 46, 131, 134, 101, 103, 105, 102, 67, 79, 74, 62, 86, 135, 153, 142, 142]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "47w4koo5lyJ4",
        "outputId": "e188d91f-01f5-4514-9f14-74bf5858f6b9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 31\n",
        "DQN_wastage = (0,41,5,191,295,357,279,642,468,583,483,449,485,498,233,344,439,404,470,250,289,246,426,493,295,293,384,270,483,313,345)\n",
        "Actor_critic = (0,318,237,247,175,212,262,170,293,239,138,145,235,222,199,176,263,238,221,236,231,236,183,211,142,176,225,278,313,227,252)\n",
        "PPO = (0,324,275,267,200,238,294,195,320,275,164,180,261,247,235,212,290,268,240,272,250,266,227,242,175,210,254,302,335,266,283)\n",
        "NAC4 = [0, 333, 207, 208, 121, 155, 215, 145, 208, 221, 86, 119, 174, 176, 179, 153, 212, 195, 168, 210, 175, 204, 167, 189, 104, 152, 195, 230, 278, 207, 209]\n",
        "NAC2 = [0, 328, 206, 218, 146, 172, 239, 123, 252, 239, 88, 129, 203, 217, 163, 129, 226, 211, 173, 221, 174, 193, 152, 171, 101, 149, 179, 204, 287, 207, 222]\n",
        "print(len(DQN_wastage))\n",
        "print(len(Actor_critic))\n",
        "print(len(PPO))\n",
        "\n",
        "ind = np.arange(N)\n",
        "ind = 2*ind\n",
        "width = 0.5\n",
        "plt.bar( ind,Actor_critic, width, label='Actor-Critic')\n",
        "plt.bar(ind + width, NAC2 , width,label='NAC_2')\n",
        "plt.bar(ind + width + width, NAC4, width,label='NAC_4')\n",
        "\n",
        "plt.ylabel('Wastage')\n",
        "#plt.title('Scores by group and gender')\n",
        "\n",
        "plt.xticks(ind + 5*width / 2, np.arange(N))\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('Shortage.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n",
            "31\n",
            "31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}