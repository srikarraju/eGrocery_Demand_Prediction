{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10kgRBLyQTzMtM7dBuY9VeepjMoWEq2py",
      "authorship_tag": "ABX9TyPYDjYbXa0o3d0mVb9eOo4G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srikarraju/eGrocery_Demand_Prediction/blob/main/NAC_eGrocery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCNrY4m-NC_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097fbb53-482a-4207-c1b9-868a5e3b8f5b"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (57.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKirrj7NNB9"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import MultivariateNormal\n",
        "import random\n",
        "import pandas as pd\n",
        "from tensorboardX import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yx9xf2fl7Vu"
      },
      "source": [
        "class EGroceryEnv():\n",
        "\n",
        "\tdef __init__(self, df=pd.DataFrame({0:[0]}), products_count=10, features=['a'], shelf_life=[1], wastage_cost=[1], shortage_cost=[1]):\n",
        "\t\tsuper(EGroceryEnv, self).__init__()\n",
        "\n",
        "\t\tself.df = df\n",
        "\t\tself.products_count = products_count\n",
        "\t\tself.shelf_life = shelf_life\n",
        "\t\tself.features = features\n",
        "\t\tself.wastage_cost = wastage_cost\n",
        "\t\tself.shortage_cost = shortage_cost\n",
        "\t\tself.current_step = 0\n",
        "\t\tself.wastage_track = list([])\n",
        "\t\tself.shortage_track = list([])\n",
        "\t\tself.reward_track = list([])\n",
        "\n",
        "\t\t#variables to track shartage and wastage\n",
        "\t\tself.shortage = np.array(list([0]*self.products_count))\n",
        "\t\tself.wastage = np.array(list([0]*self.products_count))\n",
        "\n",
        "\t\t#Define Stock\n",
        "\t\tself.stock = list([])\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tself.stock.append([0])\n",
        "\t\tprint(features)\n",
        "\n",
        "\n",
        "\tdef _next_observation(self):\n",
        "\n",
        "\t\tobs  = self.df.loc[self.current_step,self.features]\n",
        "\n",
        "\t\tst_temp = list([])\n",
        "\t\tfor i in range(len(self.stock)):\n",
        "\t\t\tfor j in range(1,min(int(self.stock[i][0])+1,5)):\n",
        "\t\t\t\tst_temp.append(self.stock[i][j])\n",
        "\t\t\tif(self.stock[i][0]==5):\n",
        "\t\t\t\tst_temp.append(self.stock[i][4])\n",
        "\t\t\telif(self.stock[i][0]<5):\n",
        "\t\t\t\tfor j in range(int(self.stock[i][0])+1,6):\n",
        "\t\t\t\t\tst_temp.append(0)\n",
        "\t\t\telse:\n",
        "\t\t\t\tst_temp.append(np.sum(self.stock[i][5:int(self.stock[i][0])+1]))\n",
        "\t\tobs = list(obs) + list(st_temp) + list(self.shelf_life)\n",
        "\t\treturn obs\n",
        "\n",
        "\tdef _take_action(self, action):\n",
        "\t\t#Add products to the current stocks\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tif(len(self.stock[i])<self.shelf_life[i]):\n",
        "\t\t\t\tfor j in range(len(self.stock[i]),int(self.shelf_life[i])):\n",
        "\t\t\t\t\tself.stock[i].append(0)\n",
        "\t\t\tself.stock[i].append(action[i])\n",
        "\t\t\tself.stock[i][0]=self.shelf_life[i]\n",
        "\n",
        "\n",
        "\n",
        "\t\t#Fullfill demand\n",
        "\t\tprods = ['prod'+str(i) for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "\t\tdemand = self.df.loc[self.current_step+1,prods]\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tfor j in range(1,int(self.stock[i][0])+1):\n",
        "\t\t\t\tif(self.stock[i][j]>=demand[i]):\n",
        "\t\t\t\t\tself.stock[i][j] = self.stock[i][j] - demand[i]\n",
        "\t\t\t\t\tdemand[i] = 0\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tdemand[i] = demand[i] - self.stock[i][j]\n",
        "\t\t\t\t\tself.stock[i][j] = 0\n",
        "\t\t\tif(demand[i]>0):\n",
        "\t\t\t\tself.shortage[i]=demand[i]\n",
        "\n",
        "\t\t#Update shelf life and find out wastage\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tself.stock[i][0] = self.stock[i][0] -1\n",
        "\t\t\tif(self.stock[i][1]>0):\n",
        "\t\t\t\tself.wastage[i] = self.stock[i][1]\n",
        "\t\t\tfor j in range(1,int(self.stock[i][0])+1):\n",
        "\t\t\t\tself.stock[i][j] = self.stock[i][j+1]\n",
        "\t\t\tself.stock[i].pop()\n",
        "\n",
        "\n",
        "\tdef step(self, action):\n",
        "\t        # update stock, fullfill demand and calculate shortage and wastage\n",
        "\t\tquantity = [6, 10, 15, 4, 6, 2, 7, 50, 2, 30]\n",
        "\t\taction1 = [0]*self.products_count\n",
        "\t\tfor i in range(len(action)):\n",
        "\t\t\taction1[i] = action[i]*quantity[i]\n",
        "\t\tself._take_action(action1)\n",
        "\t\tself.action = action\n",
        "\n",
        "\t\t#increment step\n",
        "\t\tself.current_step += 1\n",
        "\n",
        "\n",
        "\t\treward = -1*(np.matmul(self.wastage_cost,self.wastage.transpose())+np.matmul(self.shortage_cost,self.shortage.transpose()))\n",
        "\t\tself.reward = reward\n",
        "\t\tdone = (self.current_step < 0) or (self.current_step > self.df.shape[0]-2)\n",
        "\n",
        "\t\tobs = self._next_observation()\n",
        "\n",
        "\t\tself.wastage_track.append(np.sum(self.wastage))\n",
        "\t\tself.shortage_track.append(np.sum(self.shortage))\n",
        "\t\tself.reward_track.append(np.abs(self.reward))\n",
        "\n",
        "\n",
        "\t\tself.shortage = np.array(list([0]*self.products_count))\n",
        "\t\tself.wastage = np.array(list([0]*self.products_count))\n",
        "\n",
        "\t\treturn obs, np.sum(self.reward), done, {}\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\t# Reset the state of the environment to an initial state\n",
        "\t\tself.current_step = 0\n",
        "\t\tself.shortage = np.array(list([0]*self.products_count))\n",
        "\t\tself.wastage = np.array(list([0]*self.products_count))\n",
        "\t\tself.stock = list([])\n",
        "\t\tfor i in range(self.products_count):\n",
        "\t\t\tself.stock.append([0])\n",
        "\n",
        "\t\t#print(len(self.features),products_count)\n",
        "\t\t#print(self.features)\n",
        "\t\treturn [0]*len(self.features) + [0]*6*self.products_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHZRDQYNl7V3",
        "outputId": "c7802e26-db19-4cae-c011-928d044d98f7"
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/RL_Project/Models/ppo_based/PPOBased/data/final_data_trainx.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/RL_Project/Models/ppo_based/PPOBased/data/final_data_testx.csv')\n",
        "\n",
        "products_count = 10\n",
        "\n",
        "avg_f7 = ['prod'+str(i)+'avg7' for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "avg_f15 = ['prod'+str(i)+'avg15' for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "avg_f30 = ['prod'+str(i)+'avg30' for i in [8,11,15,17,94,95,96,110,112,128]]\n",
        "\n",
        "features = ['month', 'monthday', 'weekday'] + avg_f7 + avg_f15 + avg_f30\n",
        "\n",
        "print(features)\n",
        "\n",
        "shelf_life = np.array([4, 3, 5, 10, 7, 2, 1, 3, 8, 6], dtype=np.float32)\n",
        "\n",
        "wastage_cost = np.array([1]*products_count, dtype=np.float16)\n",
        "shortage_cost = np.array([1]*products_count, dtype=np.float16)\n",
        "\n",
        "action_std = 0.1\n",
        "eps_clip = 0.2\n",
        "gamma = 0.99\n",
        "\n",
        "lr = 0.0001\n",
        "betas = (0.9, 0.999)\n",
        "K_epochs = 5\n",
        "\n",
        "update_timestep = 20\n",
        "time_step=0\n",
        "running_reward = 0\n",
        "\n",
        "state_dim = len(features) + 6*products_count\n",
        "action_dim = products_count\n",
        "\n",
        "env = EGroceryEnv(df_train, products_count, features, shelf_life, wastage_cost, shortage_cost)\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "Total_reward = []\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['month', 'monthday', 'weekday', 'prod8avg7', 'prod11avg7', 'prod15avg7', 'prod17avg7', 'prod94avg7', 'prod95avg7', 'prod96avg7', 'prod110avg7', 'prod112avg7', 'prod128avg7', 'prod8avg15', 'prod11avg15', 'prod15avg15', 'prod17avg15', 'prod94avg15', 'prod95avg15', 'prod96avg15', 'prod110avg15', 'prod112avg15', 'prod128avg15', 'prod8avg30', 'prod11avg30', 'prod15avg30', 'prod17avg30', 'prod94avg30', 'prod95avg30', 'prod96avg30', 'prod110avg30', 'prod112avg30', 'prod128avg30']\n",
            "['month', 'monthday', 'weekday', 'prod8avg7', 'prod11avg7', 'prod15avg7', 'prod17avg7', 'prod94avg7', 'prod95avg7', 'prod96avg7', 'prod110avg7', 'prod112avg7', 'prod128avg7', 'prod8avg15', 'prod11avg15', 'prod15avg15', 'prod17avg15', 'prod94avg15', 'prod95avg15', 'prod96avg15', 'prod110avg15', 'prod112avg15', 'prod128avg15', 'prod8avg30', 'prod11avg30', 'prod15avg30', 'prod17avg30', 'prod94avg30', 'prod95avg30', 'prod96avg30', 'prod110avg30', 'prod112avg30', 'prod128avg30']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJbFEWJdmpdE"
      },
      "source": [
        "class policy_net(nn.Module):\n",
        "  def __init__(self,state_dim,hidden_dim,action_dim):\n",
        "    super(policy_net,self).__init__()\n",
        "    self.h = nn.Linear(state_dim,hidden_dim)\n",
        "    self.out1 = nn.Linear(hidden_dim,hidden_dim)\n",
        "    self.out2 = nn.Linear(hidden_dim,action_dim)\n",
        "    self.action_var = torch.Tensor([0.1]*10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.h(x))\n",
        "    x = F.relu(self.out1(x))\n",
        "    x = F.softmax(self.out2(x),dim=1)\n",
        "    return x\n",
        "\n",
        "  def act(self, state,action_mean):\n",
        "    state = torch.Tensor(state)\n",
        "    cov_mat = torch.diag(self.action_var)\n",
        "\n",
        "    dist = MultivariateNormal(action_mean, cov_mat)\n",
        "    action = dist.sample()\n",
        "    action_logprob = dist.log_prob(action)\n",
        "\n",
        "    return action.detach(),action_logprob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBaZMmKHmI2E"
      },
      "source": [
        "weights_v = np.zeros(93,dtype=float)\n",
        "policy = policy_net(93,512,products_count)\n",
        "optimizer = torch.optim.SGD(policy.parameters(),lr=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U0W1Z-GG4d2i",
        "outputId": "5b2df7db-26ac-447d-a69d-f092c1ac6816"
      },
      "source": [
        "# ALGORITHM 1\n",
        "alpha_0, beta_0, gamma, epsilon = 0.1, 0.01, 0.95, 0.1\n",
        "alpha_c, beta_c = 1000, 100000\n",
        "t = 0\n",
        "n_episode = 0\n",
        "actions_list = []\n",
        "avg_reward = 0\n",
        "\n",
        "while n_episode <=10000:\n",
        "  rewards,states,actions = [],[],[]\n",
        "  state = env.reset()\n",
        "  total_reward = 0\n",
        "  while True:\n",
        "    action_mean = policy(torch.tensor(state).unsqueeze(0).float()).squeeze(0)\n",
        "    #print(action_mean)\n",
        "    action,action_logprob = policy.act(state,action_mean)\n",
        "    new_state, reward, done,info = env.step(action)\n",
        "\n",
        "\n",
        "    value_curr = np.dot(weights_v,state)\n",
        "    value_next = np.dot(weights_v,new_state)\n",
        "\n",
        "    beta = (beta_0 * beta_c) / (beta_c + t)\n",
        "    alpha = (alpha_0 * alpha_c) / (alpha_c + t**(2/3))\n",
        "\n",
        "    avg_reward = (1 - alpha*gamma)* avg_reward + gamma * alpha* reward\n",
        "    td_error = reward + value_curr - value_next - avg_reward\n",
        "\n",
        "    weights_v += alpha*abs(td_error)/td_error * np.asarray(state)\n",
        "\n",
        "    policy_net_loss = -beta*abs(td_error)/td_error*action_logprob\n",
        "    optimizer.zero_grad()\n",
        "    policy_net_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_reward += reward\n",
        "\n",
        "    state = new_state\n",
        "    if done == 1:\n",
        "      break\n",
        "  print(\"Epoch:\",n_episode,\"Reward:\",total_reward)\n",
        "\n",
        "  n_episode += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Reward: -196971.0\n",
            "Epoch: 1 Reward: -196682.0\n",
            "Epoch: 2 Reward: -197426.0\n",
            "Epoch: 3 Reward: -197300.0\n",
            "Epoch: 4 Reward: -197120.0\n",
            "Epoch: 5 Reward: -196552.0\n",
            "Epoch: 6 Reward: -197233.0\n",
            "Epoch: 7 Reward: -197936.0\n",
            "Epoch: 8 Reward: -196831.0\n",
            "Epoch: 9 Reward: -197195.0\n",
            "Epoch: 10 Reward: -196042.0\n",
            "Epoch: 11 Reward: -197039.0\n",
            "Epoch: 12 Reward: -196984.0\n",
            "Epoch: 13 Reward: -196956.0\n",
            "Epoch: 14 Reward: -197372.0\n",
            "Epoch: 15 Reward: -197041.0\n",
            "Epoch: 16 Reward: -197275.0\n",
            "Epoch: 17 Reward: -196944.0\n",
            "Epoch: 18 Reward: -196637.0\n",
            "Epoch: 19 Reward: -197431.0\n",
            "Epoch: 20 Reward: -197497.0\n",
            "Epoch: 21 Reward: -197802.0\n",
            "Epoch: 22 Reward: -197565.0\n",
            "Epoch: 23 Reward: -197156.0\n",
            "Epoch: 24 Reward: -196954.0\n",
            "Epoch: 25 Reward: -196182.0\n",
            "Epoch: 26 Reward: -196467.0\n",
            "Epoch: 27 Reward: -197315.0\n",
            "Epoch: 28 Reward: -196803.0\n",
            "Epoch: 29 Reward: -197292.0\n",
            "Epoch: 30 Reward: -197718.0\n",
            "Epoch: 31 Reward: -196121.0\n",
            "Epoch: 32 Reward: -196873.0\n",
            "Epoch: 33 Reward: -196675.0\n",
            "Epoch: 34 Reward: -197804.0\n",
            "Epoch: 35 Reward: -197437.0\n",
            "Epoch: 36 Reward: -196951.0\n",
            "Epoch: 37 Reward: -196304.0\n",
            "Epoch: 38 Reward: -197452.0\n",
            "Epoch: 39 Reward: -197474.0\n",
            "Epoch: 40 Reward: -196566.0\n",
            "Epoch: 41 Reward: -197194.0\n",
            "Epoch: 42 Reward: -197179.0\n",
            "Epoch: 43 Reward: -196448.0\n",
            "Epoch: 44 Reward: -196804.0\n",
            "Epoch: 45 Reward: -195886.0\n",
            "Epoch: 46 Reward: -196876.0\n",
            "Epoch: 47 Reward: -197127.0\n",
            "Epoch: 48 Reward: -197010.0\n",
            "Epoch: 49 Reward: -197479.0\n",
            "Epoch: 50 Reward: -197340.0\n",
            "Epoch: 51 Reward: -197062.0\n",
            "Epoch: 52 Reward: -196990.0\n",
            "Epoch: 53 Reward: -196749.0\n",
            "Epoch: 54 Reward: -196168.0\n",
            "Epoch: 55 Reward: -195733.0\n",
            "Epoch: 56 Reward: -197155.0\n",
            "Epoch: 57 Reward: -197097.0\n",
            "Epoch: 58 Reward: -196494.0\n",
            "Epoch: 59 Reward: -196539.0\n",
            "Epoch: 60 Reward: -198118.0\n",
            "Epoch: 61 Reward: -196121.0\n",
            "Epoch: 62 Reward: -196996.0\n",
            "Epoch: 63 Reward: -196409.0\n",
            "Epoch: 64 Reward: -196548.0\n",
            "Epoch: 65 Reward: -197080.0\n",
            "Epoch: 66 Reward: -197173.0\n",
            "Epoch: 67 Reward: -196523.0\n",
            "Epoch: 68 Reward: -197603.0\n",
            "Epoch: 69 Reward: -196192.0\n",
            "Epoch: 70 Reward: -197927.0\n",
            "Epoch: 71 Reward: -197191.0\n",
            "Epoch: 72 Reward: -197812.0\n",
            "Epoch: 73 Reward: -196282.0\n",
            "Epoch: 74 Reward: -197050.0\n",
            "Epoch: 75 Reward: -197640.0\n",
            "Epoch: 76 Reward: -198186.0\n",
            "Epoch: 77 Reward: -196766.0\n",
            "Epoch: 78 Reward: -197352.0\n",
            "Epoch: 79 Reward: -196980.0\n",
            "Epoch: 80 Reward: -196957.0\n",
            "Epoch: 81 Reward: -196975.0\n",
            "Epoch: 82 Reward: -197194.0\n",
            "Epoch: 83 Reward: -196759.0\n",
            "Epoch: 84 Reward: -197720.0\n",
            "Epoch: 85 Reward: -196960.0\n",
            "Epoch: 86 Reward: -197170.0\n",
            "Epoch: 87 Reward: -196946.0\n",
            "Epoch: 88 Reward: -197332.0\n",
            "Epoch: 89 Reward: -197883.0\n",
            "Epoch: 90 Reward: -196281.0\n",
            "Epoch: 91 Reward: -196345.0\n",
            "Epoch: 92 Reward: -197487.0\n",
            "Epoch: 93 Reward: -196123.0\n",
            "Epoch: 94 Reward: -197448.0\n",
            "Epoch: 95 Reward: -197281.0\n",
            "Epoch: 96 Reward: -196488.0\n",
            "Epoch: 97 Reward: -196582.0\n",
            "Epoch: 98 Reward: -197277.0\n",
            "Epoch: 99 Reward: -196563.0\n",
            "Epoch: 100 Reward: -197702.0\n",
            "Epoch: 101 Reward: -196522.0\n",
            "Epoch: 102 Reward: -195780.0\n",
            "Epoch: 103 Reward: -196686.0\n",
            "Epoch: 104 Reward: -196714.0\n",
            "Epoch: 105 Reward: -197782.0\n",
            "Epoch: 106 Reward: -197461.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9cdc493f660d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0maction_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(action_mean)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_logprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-37aaa877520d>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state, action_mean)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcov_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0maction_logprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mevent_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale_tril\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy_property\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtjjxI3LwIyK"
      },
      "source": [
        "#ALGORITHM 2\n",
        "alpha_0, beta_0, gamma, epsilon = 0.1, 0.01, 0.95, 0.1\n",
        "alpha_c, beta_c = 1000, 1000\n",
        "t = 0\n",
        "n_episode = 0\n",
        "avg_reward = 0\n",
        "lamda = 0.9\n",
        "\n",
        "fischer_inv = 1.5*np.eye(6)\n",
        "state_features = generate_state_features(grid_dim)\n",
        "\n",
        "while n_episode <=15000:\n",
        "  rewards,states,actions = [],[],[]\n",
        "  state = 0\n",
        "  episode_len = 0\n",
        "  t = 0\n",
        "\n",
        "  while episode_len<100:\n",
        "    episode_len += 1\n",
        "    t += 1\n",
        "    state_action_features = generate_state_action_features(state_features[state],d,num_actions)\n",
        "\n",
        "    probs = np.dot(state_action_features,weights_p)\n",
        "    probs -= probs.max()\n",
        "    probs = np.exp(np.clip(probs/epsilon, -500, 500))\n",
        "    probs /= probs.sum()\n",
        "    probs2 = probs.cumsum()\n",
        "    action = np.where(probs2 >= np.random.random())[0][0]\n",
        "\n",
        "    new_state, reward, done = env.step(state,action)\n",
        "\n",
        "\n",
        "    value_curr = np.dot(weights_v,state_features[state])\n",
        "    value_next = np.dot(weights_v,state_features[state])\n",
        "\n",
        "    beta = (beta_0 * beta_c) / (beta_c + t)\n",
        "    alpha = (alpha_0 * alpha_c) / (alpha_c + t**(2/3))\n",
        "\n",
        "    avg_reward = (1 - alpha*gamma)*avg_reward + alpha*gamma * reward\n",
        "\n",
        "    td_error = reward + value_next - value_curr - avg_reward\n",
        "\n",
        "    weights_v += alpha * td_error * np.asarray(state_features[state])\n",
        "\n",
        "    grad_prob = probs[action]*(1-probs[action])*state_action_features[action]\n",
        "\n",
        "    Gt_psi_dot = np.dot(fischer_inv, grad_prob)\n",
        "    fischer_inv -= (0.00001*alpha * np.outer(Gt_psi_dot,Gt_psi_dot) ) / (1 - 0.00001*alpha + 0.00001*alpha * np.dot(Gt_psi_dot,grad_prob))\n",
        "    fischer_inv /= (1 - 0.00001*alpha)\n",
        "\n",
        "    weights_p += 0.1*beta * td_error * np.dot(fischer_inv,grad_prob)\n",
        "\n",
        "    states.append(state)\n",
        "    actions.append(action)\n",
        "    rewards.append(reward)\n",
        "\n",
        "    state = new_state\n",
        "    if done==1:\n",
        "      break\n",
        "\n",
        "  returns.append(np.sum(rewards))\n",
        "  if n_episode%100==0:\n",
        "    print(\"Episode: {:6d}\\tAvg. Return: {:6.2f}\".format(n_episode, np.mean(returns)))\n",
        "  rewards2.append(np.mean(returns))\n",
        "  n_episode += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqhXtiMuIdTa",
        "outputId": "4cf07522-cf3d-402e-9e2c-288ae9c94aaf"
      },
      "source": [
        "env2 = EGroceryEnv(df_test, products_count, features, shelf_life, wastage_cost, shortage_cost)\n",
        "state = env2.reset()\n",
        "for step in range(0,30):\n",
        "  state = np.asarray(state,dtype=float)\n",
        "  action_mean = policy(torch.tensor(state).unsqueeze(0).float()).squeeze(0)\n",
        "  action,action_logprob = policy.act(state,action_mean)\n",
        "  print(action)\n",
        "  next_state,reward,done,_ = env2.step(action)\n",
        "  #print(reward)\n",
        "  state = next_state\n",
        "print(env2.reward_track)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['month', 'monthday', 'weekday', 'prod8avg7', 'prod11avg7', 'prod15avg7', 'prod17avg7', 'prod94avg7', 'prod95avg7', 'prod96avg7', 'prod110avg7', 'prod112avg7', 'prod128avg7', 'prod8avg15', 'prod11avg15', 'prod15avg15', 'prod17avg15', 'prod94avg15', 'prod95avg15', 'prod96avg15', 'prod110avg15', 'prod112avg15', 'prod128avg15', 'prod8avg30', 'prod11avg30', 'prod15avg30', 'prod17avg30', 'prod94avg30', 'prod95avg30', 'prod96avg30', 'prod110avg30', 'prod112avg30', 'prod128avg30']\n",
            "tensor([-0.0756,  0.4147,  0.1228,  0.2353,  0.4955, -0.6787, -0.5794, -0.0606,\n",
            "        -0.0388, -0.3917])\n",
            "tensor([ 0.1463, -0.1173, -0.1332, -0.0124, -0.3296, -0.1962, -0.6456, -0.6367,\n",
            "        -0.3051,  1.4807])\n",
            "tensor([-0.4096, -0.2037, -0.3549,  0.2600,  0.0032,  0.2689,  0.1277,  0.1420,\n",
            "         0.2613,  1.5361])\n",
            "tensor([-0.5405, -0.6730, -0.2119, -0.0679,  0.3748, -0.6348, -0.0166,  0.0638,\n",
            "        -0.0400,  1.0583])\n",
            "tensor([ 0.2666, -0.1917, -0.2268,  0.2777,  0.3695, -0.0730, -0.0427, -0.0506,\n",
            "         0.3596,  1.3945])\n",
            "tensor([-0.2521,  0.2488,  0.1412,  0.1039,  0.0751,  0.3433, -0.2349,  0.0981,\n",
            "        -0.1389,  1.2519])\n",
            "tensor([-0.2579,  0.2547, -0.1471, -0.2253,  0.4136, -0.5506,  0.1485,  0.1211,\n",
            "        -0.1684,  0.9851])\n",
            "tensor([-0.1605,  0.1826, -0.0845,  0.3400, -0.1968,  0.1206,  0.5413,  0.0849,\n",
            "         0.5948,  0.8314])\n",
            "tensor([ 0.5610, -0.1588, -0.2213, -0.2173,  0.5250, -0.1634,  0.2155,  0.0472,\n",
            "        -0.1555,  0.6698])\n",
            "tensor([ 0.0347, -0.2438, -0.0184,  0.4954,  0.1700,  0.1412,  0.5098, -0.2623,\n",
            "         0.0687,  1.0265])\n",
            "tensor([ 0.1361,  0.1192,  0.0051, -0.1297, -0.0374, -0.2160, -0.3026, -0.3087,\n",
            "        -0.1491,  0.9902])\n",
            "tensor([ 0.2201,  0.3362,  0.7493, -0.0035,  0.2954, -0.2058, -0.6193, -0.3556,\n",
            "         0.2635,  1.2177])\n",
            "tensor([-0.1057, -0.0533, -0.0788,  0.2121, -0.3934, -0.4624, -0.4716,  0.1283,\n",
            "         0.0332,  0.9525])\n",
            "tensor([ 0.1262,  0.1241, -0.1084, -0.1353,  0.0600, -0.2285, -0.2146, -0.1126,\n",
            "        -0.0309,  1.3860])\n",
            "tensor([ 0.1862,  0.2785, -0.3503, -0.6458,  0.5330, -0.3283, -0.3250, -0.2496,\n",
            "         0.3743,  1.1813])\n",
            "tensor([ 0.1421, -0.1369, -0.1977,  0.2570,  0.1079, -0.0465, -0.3153, -0.0360,\n",
            "        -0.0862,  1.1870])\n",
            "tensor([-0.2516,  0.3480,  0.1949,  0.1279, -0.6621,  0.2706, -0.2721, -0.4276,\n",
            "         0.1158,  0.9316])\n",
            "tensor([ 0.1521, -0.8979, -0.3106,  0.0905, -0.2367,  0.4976, -0.1674,  0.3309,\n",
            "        -0.0641,  0.9592])\n",
            "tensor([-0.0181,  0.5245,  0.6439,  0.1695, -0.2377,  0.1240, -0.2788, -0.3759,\n",
            "        -0.5549,  0.6284])\n",
            "tensor([-0.8275, -0.0311,  0.1565, -0.0732, -0.0629, -0.1255,  0.1698, -0.4676,\n",
            "         0.0877,  1.2724])\n",
            "tensor([ 0.2734,  0.2235,  0.1978, -0.4854,  0.3289,  0.4678, -0.1699, -0.3644,\n",
            "        -0.0723,  1.1928])\n",
            "tensor([ 0.2737, -0.4469,  0.1360, -0.1685,  0.0528,  0.2150,  0.0107,  0.5284,\n",
            "         0.0360,  0.5278])\n",
            "tensor([ 0.0148,  0.1598, -0.0513, -0.1469, -0.7939, -0.4095, -0.3475, -0.0546,\n",
            "        -0.1719,  1.2151])\n",
            "tensor([ 0.0130,  0.1598,  0.2299, -0.1162, -0.2096, -0.6594,  0.2539, -0.0977,\n",
            "        -0.2850,  1.5476])\n",
            "tensor([-0.6956, -0.6299, -0.1844,  0.0084, -0.2757, -0.2184, -0.3506,  0.0224,\n",
            "        -0.2016,  0.4454])\n",
            "tensor([ 0.0853,  0.0494,  0.0284,  0.1343,  0.4866, -0.2148,  0.5329, -0.2393,\n",
            "        -0.2975,  0.8226])\n",
            "tensor([-0.1726,  0.0939,  0.5173, -1.0342, -0.2379, -0.3125,  0.2557, -0.2292,\n",
            "         0.1549,  0.9064])\n",
            "tensor([ 0.0338, -0.0308, -0.2567, -0.6574,  0.1447,  0.1886,  0.6066, -0.0246,\n",
            "        -0.1664,  0.7313])\n",
            "tensor([-0.1655,  0.4698, -0.3203, -0.3640,  0.0713,  0.1410, -0.3023,  0.0371,\n",
            "         0.0368,  1.3205])\n",
            "tensor([0.4263, 0.0825, 0.1948, 0.2217, 0.0870, 0.3688, 0.4707, 0.0124, 0.0123,\n",
            "        1.1872])\n",
            "[334.0, 273.0, 225.0, 177.0, 200.0, 250.0, 158.0, 286.0, 251.0, 141.0, 165.0, 229.0, 222.0, 215.0, 192.0, 247.0, 260.0, 207.0, 261.0, 238.0, 242.0, 182.0, 217.0, 145.0, 198.0, 234.0, 281.0, 315.0, 235.0, 241.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pneJEWNJEGS",
        "outputId": "835a5c83-ba41-4936-e688-71f6a505862d"
      },
      "source": [
        "print(sum(env2.reward_track)/len(env2.reward_track))\n",
        "print(env2.wastage_track)\n",
        "print(env2.shortage_track)\n",
        "print(sum(env2.wastage_track)+ sum(env2.shortage_track))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "227.36666666666667\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[334, 273, 225, 177, 200, 250, 158, 286, 251, 141, 165, 229, 222, 215, 192, 247, 260, 207, 261, 238, 242, 182, 217, 145, 198, 234, 281, 315, 235, 241]\n",
            "6821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "47w4koo5lyJ4",
        "outputId": "811bf59c-383d-47fa-8e28-9506e7cab05b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 31\n",
        "DQN_wastage = (0,41,5,191,295,357,279,642,468,583,483,449,485,498,233,344,439,404,470,250,289,246,426,493,295,293,384,270,483,313,345)\n",
        "Actor_critic = (0,318,237,247,175,212,262,170,293,239,138,145,235,222,199,176,263,238,221,236,231,236,183,211,142,176,225,278,313,227,252)\n",
        "PPO = (0,324,275,267,200,238,294,195,320,275,164,180,261,247,235,212,290,268,240,272,250,266,227,242,175,210,254,302,335,266,283)\n",
        "print(len(DQN_wastage))\n",
        "print(len(Actor_critic))\n",
        "print(len(PPO))\n",
        "\n",
        "ind = np.arange(N)\n",
        "ind = 2*ind\n",
        "width = 0.5\n",
        "plt.bar( ind,DQN_wastage, width, label='DQN')\n",
        "plt.bar(ind + width, PPO, width,label='PPO')\n",
        "plt.bar(ind + width + width, Actor_critic, width,label='Actor_critic')\n",
        "\n",
        "plt.ylabel('Wastage')\n",
        "#plt.title('Scores by group and gender')\n",
        "\n",
        "plt.xticks(ind + 5*width / 2, np.arange(N))\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('Shortage.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n",
            "31\n",
            "31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}